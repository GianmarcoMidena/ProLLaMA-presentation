\documentclass[dvipsnames,
%xcolor={svgnames},
hyperref={citecolor=blue}
]{beamer}
\beamertemplatenavigationsymbolsempty
\usetheme{Boadilla}
\usefonttheme[onlymath]{serif}

\usepackage{cleveref}

\usepackage{amsmath}
\usepackage{bm}
\usepackage{bbm}
\usepackage{mathrsfs}
\usepackage{mathtools}
\usepackage[cal=boondoxo]{mathalpha}

% Change horizontal spacing
\setlength{\tabcolsep}{3pt}

\usepackage[none]{hyphenat} % no hyphenation

\usepackage{array}

\usepackage{cancel}

\usepackage[style=authoryear,maxcitenames=2,backend=biber,citetracker=true]{biblatex}
\addbibresource{references.bib}

\usepackage{verbatim}

\usepackage{bigints}

\usepackage{makecell}

\DeclareCiteCommand{\citeauthor}
{\boolfalse{citetracker}%
	\boolfalse{pagetracker}%
	\usebibmacro{prenote}}
{\ifciteindex
	{\indexnames{labelname}}
	{}%
	\printtext[bibhyperref]{\printnames{labelname}}}
{\multicitedelim}
{\usebibmacro{postnote}}

\DeclareCiteCommand{\citeyear}
{\usebibmacro{prenote}}
{\bibhyperref{\printfield{year}}\bibhyperref{\printfield{extrayear}}}
{\multicitedelim}
{\usebibmacro{postnote}}

\newcommand{\credit}[2]{{\par\hfill \tiny #1 credit:~\itshape{\color{blue} \citeauthor{#2} (\citeyear{#2})}}}
\newcommand{\crediturl}[2]{{\par\hfill \tiny #1 credit:~\itshape{\color{blue} \url{#2}}}}
\renewcommand{\cite}[1]{({\color{blue} \citeauthor{#1}, \citeyear{#1}})}
\newcommand{\citefoot}[1]{{\color{blue} \citeauthor{#1} (\citeyear{#1})}}
\newcommand{\matr}[1]{#1}

\newcommand{\red}[1]{{\color{red} #1}}

\title[ProLLaMA]
{\href{https://doi.org/10.48550/arXiv.2402.16445}{ProLLaMA: A Protein Large Language Model for Multi-Task Protein Language Processing}}
%\subtitle{}
\author[Liuzhenghao Lv et al.]{Lv, Liuzhenghao, Zongying Lin, Hao Li, Yuyang Liu, Jiaxi Cui, Calvin Yu-Chian Chen, Li Yuan, and Yonghong Tian}
%\institute{Aalto University}
\date{3 July 2024}

\addtobeamertemplate{title page}{}{
\begin{center}
Submitted on 26 February 2024
\\\vspace{1em}Presenter: Gianmarco Midena
\end{center}}

\begin{document}
\begin{frame}
\titlepage
\end{frame}

%\begin{frame}{Outline}
%\tableofcontents
%\end{frame}

\begin{frame}{Limitations in Current LLMs for Protein Language}
	\begin{itemize}
		\item Single-task
		\item Lack Natural Language Capabilities
		\begin{itemize}
			\item Protein Language cannot fully represent all components of some tasks (User instruction, expected output)
		\end{itemize}
		\item Insufficient Instruction Understanding
		\item High Training Resource Demands
	\end{itemize}
\end{frame}

\begin{frame}{Natural Language Need}
	\begin{itemize}\setlength\itemsep{3em}
		\item Natural Language $\neq$ Protein Sequences
		\begin{itemize}\setlength\itemsep{1em}
			\item Natural language is \underline{complete} for NLP tasks
			\begin{itemize}
				\item Natural language can represent all \emph{components} for NLP tasks
				\\$\cdot$ \emph{components}: input instructions, expected output
			\end{itemize}
			\item Protein language is \underline{NOT complete} for PLP tasks
		\end{itemize}
		\item Example: protein property prediction task
		\begin{itemize}
			\item task instruction: ``Predict the property of this protein: MAFCF...FEV''
			\item expected output: ``The property is Trx superfamily.''
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Multi-task LLMs for Natural vs. Protein Language}
	\begin{center}
		\includegraphics[scale=0.5]{images/multitask_LLMs_NLP_vs_PLP.pdf}
	\end{center}
	\credit{Image}{lv2024prollama}
\end{frame}

\begin{frame}{Model}
	\begin{center}
		\includegraphics[scale=0.44]{images/model.pdf}
	\end{center}
	\credit{Image}{lv2024prollama}
\end{frame}

\begin{frame}{Learning Stages}
	\begin{center}
		\includegraphics[scale=0.39]{images/training.pdf}
	\end{center}
	\credit{Image}{lv2024prollama}
\end{frame}

\begin{frame}{Experiment Setup}
	\begin{center}
		\begin{tabular}{|c|>{\centering\arraybackslash}p{6em}|>{\centering\arraybackslash}p{6em}|>{\centering\arraybackslash}p{6em}|}\cline{2-4}
			\multicolumn{1}{c|}{} & Continual Learning & \multicolumn{2}{c|}{Instruction Tuning}\\\hline
			task & unconditional protein generation & controllable protein generation & protein property prediction \\\hline
			data source & \multicolumn{2}{c|}{UniRef50} & InterPro \\\hline
			LoRA rank & 128 & \multicolumn{2}{c|}{64} \\\hline
			epochs    & 1   & \multicolumn{2}{c|}{2} \\\hline
			optimizer & \multicolumn{3}{c|}{AdamW} \\\hline
			scheduler & \multicolumn{3}{c|}{Cosine Annealing with Warmup} \\\hline
			%peak learning rate & \multicolumn{2}{c|}{0.05} \\\hline
		\end{tabular}
	\end{center}
\end{frame}

\input{sections/evaluation_metrics.tex}

\input{sections/protein_structure_levels.tex}

\input{sections/data.tex}

\begin{frame}{Performance in (Unconditional) Protein Generation}
	\begin{center}
		\includegraphics[scale=0.21]{tables/methods_comparison.png}
		\begin{tabular}{>{\centering\arraybackslash}p{11.7em}|>{\centering\arraybackslash}p{3.1em}>{\centering\arraybackslash}p{2.7em}|>{\centering\arraybackslash}p{2.3em}>{\centering\arraybackslash}p{2.3em}|>{\centering\arraybackslash}p{2.3em}>{\centering\arraybackslash}p{2.3em}}
		{\scriptsize \makecell{Natural protein \\ \cite{alamdari2023protein}}} & \scalebox{.55}{\underline{68.25$\pm$17.85}} & \scalebox{.55}{3.09$\pm$0.63} & & & & \\\hline
		\end{tabular}
	\end{center}
	%\credit{Table}{lv2024prollama}
	\begin{itemize}
		\item ProLLaMA can generate proteins
		\begin{itemize}
			\item Structurally plausible
			\item Comparable to natural proteins
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Quality of Generated Protein w.r.t. Length}%ProLLaMA vs. ESM2 (Baseline) Model}
%\begin{center}
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\includegraphics[scale=0.23]{images/combined_length_plddt_zhexiantu.pdf}
			\includegraphics[scale=0.23]{images/combined_length_alntmscore_zhexiantu.pdf}
		\end{column}
		\begin{column}{0.5\textwidth}
			\includegraphics[scale=0.23]{images/combined_length_scperp_zhexiantu.pdf}
			\begin{itemize}
				\item ProLLaMA is able to capture long-range dependencies between amino acids
			\end{itemize}
		\end{column}
	\end{columns}
%\end{center}
\vspace{-2em}\credit{Image}{lv2024prollama}
\end{frame}

\begin{frame}{Performance in Controllable Protein Generation}% on Four Different Instructions
	\begin{center}
		\includegraphics[scale=0.21]{tables/controlled_generation_comparison.png}
	\end{center}
	\vspace{-1em}\credit{Table}{lv2024prollama}
	\begin{itemize}
		\item Given one instruction, \\ProLLaMA generates proteins with the desired functionalities
		\item High metrics mean proteins meet instructions
		\item Other models: uncontrollable generation
		\item Instructions: four superfamily descriptions
		%What do superfamilies are?
		\begin{itemize}
			\item SAM-MT: S-adenosyl-L-methionine-dependent methyltransferase
			\item TPHD: Tetratricopeptide-like helical domain
			\item Trx: Thioredoxin-like 
			\item CheY: CheY-like
		\end{itemize}
	\end{itemize}
\end{frame}

\begin{frame}{Generated vs. Natural Protein}
	\begin{columns}
		\begin{column}{0.5\textwidth}
			\includegraphics[scale=0.7]{images/d.png}
			\includegraphics[scale=0.7]{images/f.png}'
		\end{column}
		\begin{column}{0.5\textwidth}
			\includegraphics[scale=0.7]{images/e.png}
			\begin{itemize}
				\item Proteins generated by ProLLaMA are comparable to their
				natural counterparts in the same superfamily
			\end{itemize}
		\end{column}
	\end{columns}
	\credit{Image}{lv2024prollama}
\end{frame}

\begin{frame}{Visualization of Controllable Generated vs. Natural Proteins}
	\begin{center}
		\includegraphics[trim={0 0 90em 0},clip,scale=0.4]{images/protein_visualization.pdf}
		\includegraphics[trim={31.5em 0 57.4em 0},clip,scale=0.4]{images/protein_visualization.pdf}
		\includegraphics[trim={64em 0 30em 0},clip,scale=0.4]{images/protein_visualization.pdf}
		\includegraphics[trim={92em 0 0 0},clip,scale=0.4]{images/protein_visualization.pdf}
	\end{center}
	\vspace{-1em}\credit{Image}{lv2024prollama}
	\begin{itemize}
		\item Blue: generated proteins, yellow: natural proteins
		\item Similar in structure (function), different in sequence (novel)
	\end{itemize}
\end{frame}

\begin{frame}{Performance in Protein Property Prediction}
	\begin{center}
		\begin{tabular}{cc}\hline
			Property & Accuracy (\%) \\\hline
			OBFD     & 100 \\
			UPF0145  & 100 \\
			NACD     & 100 \\
			U3S      & 100 \\
			CCHC     & 95.24  \\
			Kazal    & 100 \\
			SAM-MT   & 93.67  \\
			TPHD     & 90.84  \\
			Trx      & 94.17  \\
			CheY     & 100 \\\hline
		\end{tabular}
	\end{center}
	\credit{Table}{lv2024prollama}
	\begin{itemize}
		\item Property = superfamily
	\end{itemize}
\end{frame}

\input{sections/summary.tex}

\begin{frame}{Sequences Generated w/o Instructions - Distributions}
	\begin{center}
		\includegraphics[scale=0.35]{images/plddt_scperp.pdf}
		\includegraphics[scale=0.35]{images/tm_sid.pdf}
	\end{center}
	\credit{Image}{lv2024prollama}
	\begin{itemize}
		\item 1 spot = 1 sequence
	\end{itemize}
\end{frame}

\begin{frame}{Natural Language Ability}
	\begin{center}
		\includegraphics[scale=0.21]{tables/natural_language_ability_comparison.png}
	\end{center}
	\credit{Table}{lv2024prollama}
	\begin{itemize}
		\item Sentence generation on Wikipedia text
	\end{itemize}
\end{frame}

\section{References}
\begin{frame}[allowframebreaks]
\frametitle{References}
\printbibliography
\end{frame}

\end{document}